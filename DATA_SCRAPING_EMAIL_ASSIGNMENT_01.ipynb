{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1f07ca",
   "metadata": {},
   "source": [
    "# Scraping All Emails of All FAST NUCES CAMPUSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6f9ea",
   "metadata": {},
   "source": [
    "This Python script utilizes the requests library to fetch the HTML content of a webpage, then utilizes BeautifulSoup and re to parse and extract data from the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f45643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admissions.cfd@nu.edu.pk\n",
      "admissions.isb@nu.edu.pk\n",
      "admissions.khi@nu.edu.pk\n",
      "admissions.lhr@nu.edu.pk\n",
      "admissions.pwr@nu.edu.pk\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1bcf96",
   "metadata": {},
   "source": [
    "This variable url contains the web address for the contact page of the National University website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the NU website\n",
    "url = 'https://www.nu.edu.pk/home/ContactUs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d135a9e",
   "metadata": {},
   "source": [
    "\n",
    "This code sends a GET request to the specified URL, retrieves the HTML content of the webpage, and stores it in the variable html_content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the HTML content of the website\n",
    "response = requests.get(url)\n",
    "html_content = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab5dd6",
   "metadata": {},
   "source": [
    "\n",
    "This code utilizes BeautifulSoup library to parse the HTML content retrieved from the website, enabling further extraction and manipulation of its elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917237c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a610a61",
   "metadata": {},
   "source": [
    "\n",
    "This code extracts all the visible text content from the parsed HTML using BeautifulSoup and stores it in the variable text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66db8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all text within the HTML content\n",
    "text = soup.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f76a4",
   "metadata": {},
   "source": [
    "This regular expression pattern (email_pattern) is designed to match email addresses within a text.\n",
    "1. It starts with \\b to denote a word boundary.\n",
    "2. [A-Za-z0-9._%+-]+ matches one or more alphanumeric characters, dots, underscores, percentage signs, plus signs, or hyphens, which are common characters in email addresses.\n",
    "@ matches the \"@\" symbol.\n",
    "3. [A-Za-z0-9.-]+ matches one or more alphanumeric characters, dots, or hyphens, which are typically found in the domain part of email addresses.\n",
    "4. \\. matches a dot, which separates the domain name from the top-level domain (TLD).\n",
    "5. [A-Z|a-z]{2,} matches the TLD, ensuring it consists of at least two letters, whether uppercase or lowercase.\n",
    "6. \\b again denotes a word boundary, ensuring the match ends correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad874d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression pattern to match email addresses\n",
    "email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9fb70e",
   "metadata": {},
   "source": [
    "\n",
    "This code utilizes the defined regular expression pattern to find all email addresses within the extracted text and stores them in the variable emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e713fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all email addresses in the text using the regular expression\n",
    "emails = re.findall(email_pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c521adf6",
   "metadata": {},
   "source": [
    "\n",
    "This loop iterates over each email address in the emails list and prints each one individually.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the extracted email addresses\n",
    "for email in emails:\n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff814f0",
   "metadata": {},
   "source": [
    "The Python script provided performs web scraping to extract email addresses from the contact page of the National University (NU) website. Initially, the script employs the requests library to fetch the HTML content of the specified URL, storing it in the variable html_content. Subsequently, utilizing the BeautifulSoup library, the HTML content is parsed into a BeautifulSoup object named soup, facilitating efficient traversal and manipulation of HTML elements. The script then extracts all visible text content from the parsed HTML using the soup.get_text() method, consolidating it into the variable text. To identify email addresses within the extracted text, a regular expression pattern (email_pattern) is defined, ensuring accurate matching based on common email formatting conventions. The re.findall() function is subsequently employed with the defined email_pattern to search for and extract all email addresses present in the text, storing the matches in the emails variable as a list. Finally, a loop iterates over each extracted email address in the emails list, printing them individually. This script exemplifies a basic yet effective approach to web scraping, demonstrating the utilization of Python libraries to programmatically extract desired information from web pages, in this case, email addresses from the NU contact page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
